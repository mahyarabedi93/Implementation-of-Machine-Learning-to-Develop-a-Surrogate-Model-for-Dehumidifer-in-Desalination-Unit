{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22825e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import time\n",
    "from numpy import linalg as LA\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.kernel_ridge import  KernelRidge\n",
    "from sklearn.linear_model import  HuberRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69759975",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Input\n",
    "\n",
    "df1 = pd.read_csv('Input.csv')\n",
    "\n",
    "df1.rename(columns = {'TLI':'InletLiquidTemperature', 'TAI':'InletAirTemperature'\n",
    "                   , 'H':'PackedBedHeight' , 'D':'PackedBedDiameter', 'ML':'LiquidMassFlow'\n",
    "                   , 'MA':'AirMassFlow', 'EPS':'PackedBedPorosity'}, inplace = True)\n",
    "\n",
    "X = df1.to_numpy() #Input\n",
    "\n",
    "#Reading Output\n",
    "\n",
    "df2 = pd.read_csv('Output.csv')\n",
    "\n",
    "df2.rename(columns = {'TLO':'OutletLiquidTemperature', 'TAO':'OutletAirTemperature'}, inplace = True)\n",
    "\n",
    "Y = df2.to_numpy() \n",
    "# Y = Y0[:,0]\n",
    "\n",
    "df3 = pd.concat([df1, df2], axis=1, join=\"inner\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225dd7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "# Best linear estimation\n",
    "reg = MultiOutputRegressor(LinearRegression()).fit(X, Y)\n",
    "linear_score=reg.score(X, Y)\n",
    "print(linear_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5dc1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_stand_scaler_obj = StandardScaler()\n",
    "my_stand_scaler_obj.fit(X_train)\n",
    "\n",
    "# rescale the training data\n",
    "X_stand_scaler = my_stand_scaler_obj.transform(X)\n",
    "\n",
    "# rescale the training data\n",
    "X_train_stand_scaler = my_stand_scaler_obj.transform(X_train)\n",
    "\n",
    "# also, rescale the training data\n",
    "X_test_stand_scaler = my_stand_scaler_obj.transform(X_test)\n",
    "\n",
    "\n",
    "print(my_stand_scaler_obj.mean_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31517abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KRR  = KernelRidge(alpha=.01, kernel='rbf')\n",
    "sVR1 = SVR(kernel='rbf', degree=10, C=1.0, epsilon=1)\n",
    "sVR2 = SVR(kernel='rbf', degree=10, C=1.0, epsilon=0.1)\n",
    "sVR3 = SVR(kernel='rbf', degree=10, C=1.0, epsilon=0.01)\n",
    "sVR4 = SVR(kernel='rbf', degree=10, C=1.0, epsilon=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf2b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "time_start = time.time()\n",
    "train_sizes, train_scores, test_scores = learning_curve(sVR1,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"neg_mean_squared_error\",\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "time_elapsed = (time.time() - time_start)\n",
    "print('time_elapsed=', time_elapsed)\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean1 = np.mean(train_scores, axis=1).reshape(-1,1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean1 = np.mean(test_scores, axis=1).reshape(-1,1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998158a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_start = time.time()\n",
    "SVR1 = MultiOutputRegressor(SVR(kernel='rbf', degree=10, C=1.0, epsilon=1))#(kernel='poly', degree=5, C=1.0, epsilon=1))\n",
    "SVR1.fit(X_train_stand_scaler,Y_train)\n",
    "time_elapsed = (time.time() - time_start)\n",
    "print('time_elapsed=', time_elapsed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0af62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_SVR_Predict=SVR1.predict(X_test_stand_scaler)\n",
    "MSE_SVR=mean_squared_error(Y_test,Y_SVR_Predict)\n",
    "# MAE_SVR=mean_absolute_error(Y_test,Y_SVR_Predict)\n",
    "R2_SVR=r2_score(Y_test,Y_SVR_Predict)\n",
    "Score_SVR=SVR1.score(X_test_stand_scaler,Y_test)\n",
    "print(MSE_SVR)\n",
    "# print(MAE_Lin)\n",
    "print(R2_SVR)\n",
    "print(Score_SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6f3b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(sVR1,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"r2\", \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean1 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean1 = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad9c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(sVR2,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"neg_mean_squared_error\", \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean2 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean2 = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ac2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(sVR2,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"neg_mean_squared_error\", \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean2 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean2 = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69edb505",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(sVR3,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"neg_mean_squared_error\", \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean3 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean3 = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9de2e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "A=test_mean3.reshape(-1,1)\n",
    "D=train_mean3.reshape(-1,1)\n",
    "A.shape\n",
    "B=np.linspace(0.1, 0.9, 51).reshape(-1,1)\n",
    "\n",
    "C=np.append(D,A,axis=1)\n",
    "print(C)\n",
    "C=np.append(C,B,axis=1)\n",
    "print(C)\n",
    "\n",
    "df = pd.DataFrame(C, columns = ['trainsize','Training MSE','Test MSE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b8140b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(sVR4,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"neg_mean_squared_error\", \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean4 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean4 = np.mean(test_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f3fd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes, train_scores, test_scores = learning_curve(KRR,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        scoring=\"neg_mean_squared_error\", \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean5 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean5 = np.mean(test_scores, axis=1)\n",
    "\n",
    "print(test_mean5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d159e35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "# draw basic lines\n",
    "plt.plot(train_sizes, test_mean1, label='SVR, $\\epsilon=1$')\n",
    "plt.plot(train_sizes, test_mean2, label='SVR, $\\epsilon=0.1$')\n",
    "plt.plot(train_sizes, test_mean3, label='SVR, $\\epsilon=0.01$')\n",
    "plt.plot(train_sizes, test_mean4, label='SVR, $\\epsilon=0.001$')\n",
    "#plt.plot(train_sizes, test_mean4, label='Huber')\n",
    "#plt.plot(train_sizes, test_mean5, '--', color='k', label='KRR, $\\\\alpha=0.01$')\n",
    "         \n",
    "plt.xlabel('Training Set Size',fontsize=18)\n",
    "plt.ylabel('Neg. MSE Score',fontsize=18)\n",
    "plt.title('Learning Curves -- C.V. Scores',fontsize=22)\n",
    "plt.legend(loc=\"best\",fontsize=15)\n",
    "plt.grid(which='both',axis='both',color='grey', linestyle='--', linewidth=.3)\n",
    "\n",
    "plt.savefig('LC_SVRs_MSE_kernels.png', dpi=400, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        metadata=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ad9e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mean1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2acd570d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%############################################################################\n",
    "\n",
    "\n",
    "# Notice how this is set up - there are a lot of options, which makes the ML workflow\n",
    "# complex, but also very powerful.\n",
    "# from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(sVR1,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean1 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean1 = np.mean(test_scores, axis=1)\n",
    "\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(sVR2,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10, \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean2 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean2 = np.mean(test_scores, axis=1)\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(sVR3,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10, \n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean3 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean3 = np.mean(test_scores, axis=1)\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(sVR4,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean4 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean4 = np.mean(test_scores, axis=1)\n",
    "\n",
    "\n",
    "train_sizes, train_scores, test_scores = learning_curve(KRR,\n",
    "                                                        X_stand_scaler, Y,\n",
    "                                                        cv = 10,\n",
    "                                                        train_sizes = np.linspace(0.1, 0.9, 51))\n",
    "\n",
    "# Means and standard deviations of training set scores\n",
    "train_mean5 = np.mean(train_scores, axis=1)\n",
    "# Means and standard deviations of test set scores\n",
    "test_mean5 = np.mean(test_scores, axis=1)\n",
    "\n",
    "\n",
    "#%%############################################################################\n",
    "\n",
    "fig = plt.figure(figsize=(9, 6))\n",
    "\n",
    "# draw basic lines\n",
    "plt.plot(train_sizes, test_mean1, label='SVR, $\\epsilon=1$')\n",
    "plt.plot(train_sizes, test_mean2, label='SVR, $\\epsilon=0.1$')\n",
    "plt.plot(train_sizes, test_mean3, label='SVR, $\\epsilon=0.01$')\n",
    "plt.plot(train_sizes, test_mean4, label='SVR, $\\epsilon=0.001$')\n",
    "#plt.plot(train_sizes, test_mean4, label='Huber')\n",
    "plt.plot(train_sizes, test_mean5, '--', color='k', label='KRR, $\\\\alpha=0.01$')\n",
    "         \n",
    "plt.xlabel('\\\\textbf{Training Set Size}',fontsize=18)\n",
    "plt.ylabel('\\\\textbf{R$_2$ Score}',fontsize=18)\n",
    "plt.title('\\\\textbf{Learning Curves -- C.V. Scores}',fontsize=22)\n",
    "plt.legend(loc=\"best\",fontsize=15)\n",
    "plt.grid(which='both',axis='both',color='grey', linestyle='--', linewidth=.3)\n",
    "\n",
    "plt.savefig('LC_SVRs_R2_kernels.png', dpi=400, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        metadata=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
